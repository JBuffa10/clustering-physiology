---
title: "CART"
author: "Jacob Buffa"
date: "March 21, 2020"
output: html_document
---

## MODEL OBJECTIVE
<p> I have a subset of athltes that after training and watching for over a year, I am confident in their physiology, movement strategies, and they fit the logic derived from the Performance Driver metrics.  There is another subst of athletes that I am also confident in their movement strategies, but they are slightly off from the performance driver logic.  I am hoping to find a model that can identify a pattern that I am not recognizing to correctly classify all athletes.<p>
<br>
A bagged CART model was chosen first because there are no tuning parameters. Thought of as a 'baseline'.  Now a simple rpart classification tree is selected in order to view and analyze decision making proces of the model
<br>

### Load Libraries & Data
```{r libraries, message=FALSE, warning=FALSE}
library(caret)
library(rpart)
library(tidyverse)
library(rattle)
library(rpart.plot)

# Scoring Function
custom.scoring <- function(x){
  scale(x)*10+50
}

# Tables
athleteInfo <- read.csv("AthleteInformation1.csv")
allData <- read.csv("FINAL TABLE.csv")
```

### Data Processing
```{r process, warning=FALSE, message=FALSE}
# ORGANIZE 
athleteInfo <-
  athleteInfo %>%
  transform(Birthday = as.Date(Birthday, format = "%m/%d/%Y")) %>%
  mutate(Gender = ifelse(Gender == "F", "F","M"))

masterData <- 
  allData %>%
  mutate(Avg..Relative.Braking.Force = (Avg..Braking.Force/System.Weight)*100,
         Avg..Relative.Braking.Power = Avg..Braking.Power/System.Weight,
         Avg..Relative.Propulsive.Power = Avg..Propulsive.Power/System.Weight) %>%
  transform(Date = as.Date(Date, format = "%m/%d/%Y"),
            Name = as.character(Name)) %>%
  left_join(athleteInfo, by = "Name") %>%
  filter(Gender == "M")

variables <- colnames(masterData)
brakingMetrics <- variables[c(5:7,12,13,16,17,19)]
propulsiveMetrics <- variables[c(9:11,14,15,47,53:55)]
balanceMetrics <- variables[c(25:34)]

# CENTER AND SCALE
clusterData <- masterData %>% 
  mutate_at(vars(brakingMetrics,propulsiveMetrics), custom.scoring) %>%
  group_by(Name) %>%
  summarise_at(vars(brakingMetrics, propulsiveMetrics), mean, na.rm = TRUE)
clusterData <- na.omit(clusterData) # remove NA

# IDENTIFY CORRELATED PREDICTORS
cormatrix <- cor(clusterData[,-1])
summary(cormatrix[upper.tri(cormatrix)])
#highlyCor <- findCorrelation(cormatrix, cutoff = .8) 
#filterclusterData <- clusterData[,-highlyCor]
```
Data has been cleaned, centered, and scaled for the model.  Normally would elimate linear dependencies, but Performance Driver metrics have been selected based on domain expertise
<br> 

```{r assign labels, message=FALSE, warning=FALSE}
labels <- 
  clusterData %>%
  mutate(Class = case_when(Takeoff.Velocity > Avg..Propulsive.Velocity+2 &
                             Avg..Propulsive.Force > Avg..Propulsive.Velocity+2 ~ 'Momentum',
                           Takeoff.Velocity <= Avg..Propulsive.Velocity+2 &
                             Avg..Propulsive.Force <= Avg..Propulsive.Velocity+2 &
                             Avg..Braking.Force < Avg..Braking.Velocity-2 ~ 'Power',
                           Takeoff.Velocity <= Avg..Propulsive.Velocity+2 &
                             Avg..Propulsive.Force <= Avg..Propulsive.Velocity+2 &
                             Avg..Braking.Force >= Avg..Braking.Velocity-2 ~ 'Athletic')) %>%
  select(Name, Class)

treeData <-
  masterData %>% 
  mutate_at(vars(brakingMetrics,propulsiveMetrics), custom.scoring) %>%
  group_by(Name, Date) %>%
  summarise_at(vars(brakingMetrics, propulsiveMetrics), mean, na.rm = TRUE) %>%
  left_join(labels, by = 'Name') %>%
  ungroup() %>%
  mutate(Class = ifelse(is.na(Class), 'Unknown',Class)) %>%
  group_by(Name) %>%
  mutate(Per = n()/1118) %>%
  mutate(Outlier = ifelse(Per > .02 & Avg..Propulsive.Force <= quantile(Avg..Propulsive.Force, .6, na.rm = TRUE),1,0)) %>%
  filter(Outlier == 0) %>%
  select(Name, Avg..Braking.Force, Avg..Braking.Velocity, Avg..Relative.Braking.Force, Avg..Propulsive.Force, 
         Avg..Relative.Propulsive.Force, Avg..Propulsive.Velocity,Avg..Propulsive.Force, Takeoff.Velocity,
         Class) %>% na.omit()
```
Condense data to assign labels to the athletes that I am confident in, and fit the logic derived from Performance Driver metrics.  Then expand data back to have more data points to train the model.  Identify Athletes that have enough tests to bias the sample, and only keep the top 40% of their tests.  Finally, remove and NA values
<br>


### Data Splitting

```{r training_testing, message=FALSE, warning=FALSE}
train.tree <- treeData[,-1] %>% filter(Class != 'Unknown')
test.tree <- treeData[,-1] %>% filter(Class == 'Unknown')
```
Ideally these would be random splits.  But for the purposes of this model, I have split the training set and testing set based on athletes with and without pre-assigned labels
<br>

### Model Training & Tuning
```{r model, message=FALSE, warning=FALSE}
# Resampling method of repeated cross validation
fitControl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10
)

# Model Training
set.seed(234)
cart.model <- train(Class ~., data = train.tree,
                    method = 'rpart', 
                    minsplit = 0,
                    cp = 0,
                    trControl = fitControl)

cart.model
```

```{r plot model}
plot(cart.model$finalModel)
text(cart.model$finalModel)
```
<br>

### Predicting Outcomes
```{r}
# get predicted labels
cart.pred <- predict.train(cart.model, newdata = test.tree)

# Distribution of predicted labels
sum(cart.pred == 'Athletic')
sum(cart.pred == 'Power')
sum(cart.pred == 'Momentum')

# assign labels to athletes and view results
treeData %>%
  filter(Class == 'Unknown') %>%
  select(Name)%>%
  add_column(pred.class = cart.pred) %>% view()

```
<br>

### Conclusion
<i>This model performed better than the bagged CART model, but still not optimally.  Seemed to misclassify some momentum athletes as athletic.  It was very interesting and insightful to see the logic being used for the tree was only braking velocity vs. force.  The next step is to re-run the model, but add in a propulsive velocity difference metric.  Maybe strip away all other metrics aside from the velo difference and braking velo and braking force.<i>
<br>
<br>

### Model 2 Training & Tuning
```{r model 2, message=FALSE, warning=FALSE}
# add velo difference as a variables
treeData.2 <-
  masterData %>% 
  mutate_at(vars(brakingMetrics,propulsiveMetrics), custom.scoring) %>%
  group_by(Name, Date) %>%
  summarise_at(vars(brakingMetrics, propulsiveMetrics), mean, na.rm = TRUE) %>%
  left_join(labels, by = 'Name') %>%
  ungroup() %>%
  mutate(Class = ifelse(is.na(Class), 'Unknown',Class)) %>%
  group_by(Name) %>%
  mutate(Per = n()/1118) %>%
  mutate(Outlier = ifelse(Per > .02 & Avg..Propulsive.Force <= quantile(Avg..Propulsive.Force, .6, na.rm = TRUE),1,0)) %>%
  filter(Outlier == 0) %>%
  mutate(Propulsive.Velo.Diff = Avg..Propulsive.Velocity - Takeoff.Velocity) %>%
  select(Name, Avg..Braking.Force, Avg..Braking.Velocity, Avg..Relative.Braking.Force, Avg..Propulsive.Force, 
         Avg..Relative.Propulsive.Force, Avg..Propulsive.Velocity,Avg..Propulsive.Force, Takeoff.Velocity,
         Propulsive.Velo.Diff,Class) %>% na.omit()

train.tree.2 <- treeData.2[,-1] %>% filter(Class != 'Unknown')
test.tree.2 <- treeData.2[,-1] %>% filter(Class == 'Unknown')

# Resampling method of repeated cross validation
fitControl <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10
)

# Model Training
set.seed(234)
cart.model.2 <- train(Class ~., data = train.tree.2,
                    method = 'rpart', 
                    minsplit = 0,
                    cp = 5,
                    trControl = fitControl)

cart.model.2

```


```{r plot model.2}
plot(cart.model.2$finalModel)
text(cart.model.2$finalModel)
```


<br>

### Predicting Outcomes
```{r}
# get predicted labels
cart.2.pred <- predict.train(cart.model.2, newdata = test.tree.2)

# Distribution of predicted labels
sum(cart.2.pred == 'Athletic')
sum(cart.2.pred == 'Power')
sum(cart.2.pred == 'Momentum')

# assign labels to athletes and view results
treeData %>%
  filter(Class == 'Unknown') %>%
  select(Name)%>%
  add_column(pred.class = cart.2.pred) %>% view()

```
<br>

### Conclusion
<i>
This model was slightly more accurate than the first.  The second branch used the Velocity difference variable instead of braking force which made it more accurate.  The next thought now is that I either need to take a harder look at the athlete clusters to see if I may have misclassified some.  It is possible that I am not misunderstanding some qualities between "Power" and "Athletic".  The alternative is to figure out a way to get the model to prioritize Velocity difference over braking velocity.  It seems that would make it the most accurate and complete the model.
<i>
<br>
<br>